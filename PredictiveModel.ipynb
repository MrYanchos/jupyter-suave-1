{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuAVE Image to Label CNN Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function getQueryStringValue (key)\n",
       "{  \n",
       "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
       "}\n",
       "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
       "//IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "//IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "#from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\n",
    "\t\t# first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "              \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(1000))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the number of epochs to train for, init learning rate and batch size\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-3\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# init the image suffix, yset, and image list\n",
    "print(\"[INFO] loading images...\")\n",
    "suffix = '.jpg'\n",
    "img_list = []\n",
    "yset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels list and 2 dicts for 2 way mapping\n",
    "labels = []\n",
    "# key = label value = number\n",
    "label_yval = dict()\n",
    "# key = number value = label\n",
    "yval_label = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Cells\n",
    "csv_file = 'balthus_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use csv file to grab images/labels\n",
    "df = pd.read_csv(csv_file)\n",
    "nameCol = df['#img']\n",
    "predCol = df['Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all fabric columns to the y set\n",
    "for i in range (0,len(predCol)):\n",
    "    labels.append(predCol[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all unique labels\n",
    "uni_labels = set(labels)\n",
    "uni_labels = list(uni_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each label a dict key number\n",
    "for i in range(0,len(uni_labels)):\n",
    "    yval_label[i] = uni_labels[i]\n",
    "    label_yval[uni_labels[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Expressionism': 1,\n",
       " 'Expressionism, Japonism': 2,\n",
       " 'Expressionism, Surrealism': 6,\n",
       " 'Metaphysical art': 5,\n",
       " 'Metaphysical art, Surrealism': 4,\n",
       " 'Realism': 3,\n",
       " 'Surrealism': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_yval[labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of keys associated with their labels\n",
    "for i in range (0, len(labels)):\n",
    "    yset.append(label_yval[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove text and leave fabric cave number for labels and zero index\n",
    "#for i in range (0,len(yset)):\n",
    "#    yset[i] = int(re.sub(\"\\D\", \"\", yset[i]))\n",
    "#    yset[i] = yset[i]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather images from path created from file names in csv file\n",
    "for i in range (0,len(nameCol)):\n",
    "    base_filename = nameCol[i]\n",
    "    fileName = os.path.join(\"./images3/\", base_filename + suffix)\n",
    "    im = cv2.imread(fileName)\n",
    "    im = cv2.resize(im, (28,28))\n",
    "    im = img_to_array(im)\n",
    "    img_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "p = np.random.permutation(len(yset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(yset)):\n",
    "    Y.append(yset[p[i]])\n",
    "    X.append(img_list[p[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the test and training set 75:25\n",
    "split = int(len(X)*(.75))\n",
    "xtrain = X[:split]\n",
    "xtest = X[split:]\n",
    "ytrain = Y[:split]\n",
    "ytest = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to arrays\n",
    "trainX = np.array(xtrain, dtype=\"float\")/225.0\n",
    "testX = np.array(xtest, dtype =\"float\")/225.0\n",
    "\n",
    "ytrain = np.array(ytrain)\n",
    "ytest = np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28, 28, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed Y data containers\n",
    "trainY = []\n",
    "testY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels from int to vectors\n",
    "trainY = np_utils.to_categorical(ytrain,12)\n",
    "testY = np_utils.to_categorical(ytest,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=28, height=28, depth=3, classes=12)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 2.4001 - acc: 0.1667 - val_loss: 1.2565 - val_acc: 0.8750\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 1.2854 - acc: 0.8281 - val_loss: 1.1544 - val_acc: 0.8750\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.0865 - acc: 0.8438 - val_loss: 1.2200 - val_acc: 0.8750\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.3396 - acc: 0.5000 - val_loss: 0.8612 - val_acc: 0.8750\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.8687 - acc: 0.8125 - val_loss: 0.9284 - val_acc: 0.8750\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8891 - acc: 0.8333 - val_loss: 1.1222 - val_acc: 0.8750\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.1896 - acc: 0.6667 - val_loss: 1.2080 - val_acc: 0.8750\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 1.1383 - acc: 0.8281 - val_loss: 1.1206 - val_acc: 0.8750\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.3182 - acc: 0.8333 - val_loss: 0.9754 - val_acc: 0.8750\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.8706 - acc: 0.8125 - val_loss: 0.8859 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7589 - acc: 0.8281 - val_loss: 0.9372 - val_acc: 0.8750\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.5986 - acc: 0.6667 - val_loss: 0.9605 - val_acc: 0.8750\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0589 - acc: 1.0000 - val_loss: 1.0057 - val_acc: 0.8750\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.9493 - acc: 0.7969 - val_loss: 1.0016 - val_acc: 0.8750\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.8039 - acc: 0.8281 - val_loss: 0.9704 - val_acc: 0.8750\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.7219 - acc: 0.6667 - val_loss: 0.9178 - val_acc: 0.8750\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1733 - acc: 1.0000 - val_loss: 0.9117 - val_acc: 0.8750\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.7895 - acc: 0.7969 - val_loss: 0.9193 - val_acc: 0.8750\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.7467 - acc: 0.8281 - val_loss: 0.9315 - val_acc: 0.8750\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.2316 - acc: 0.6667 - val_loss: 0.9529 - val_acc: 0.8750\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.8242 - acc: 0.8125 - val_loss: 0.9683 - val_acc: 0.8750\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7337 - acc: 0.8333 - val_loss: 0.9724 - val_acc: 0.8750\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.8236 - acc: 0.8125 - val_loss: 0.9692 - val_acc: 0.8750\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7655 - acc: 0.8333 - val_loss: 0.9655 - val_acc: 0.8750\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.7405 - acc: 0.8281 - val_loss: 0.9728 - val_acc: 0.8750\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.1164 - acc: 0.6667 - val_loss: 0.9784 - val_acc: 0.8750\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6125 - acc: 0.8333 - val_loss: 0.9870 - val_acc: 0.8750\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.8194 - acc: 0.8125 - val_loss: 0.9973 - val_acc: 0.8750\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7423 - acc: 0.8125 - val_loss: 1.0089 - val_acc: 0.8750\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.8840 - acc: 0.8333 - val_loss: 1.0179 - val_acc: 0.8750\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2293 - acc: 1.0000 - val_loss: 1.0420 - val_acc: 0.8750\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.8577 - acc: 0.7969 - val_loss: 1.0572 - val_acc: 0.8750\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.8078 - acc: 0.8281 - val_loss: 1.0567 - val_acc: 0.8750\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.0823 - acc: 0.6667 - val_loss: 1.0327 - val_acc: 0.8750\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 0.8482 - acc: 0.7969 - val_loss: 1.0066 - val_acc: 0.8750\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1432 - acc: 1.0000 - val_loss: 0.9988 - val_acc: 0.8750\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.7821 - acc: 0.8125 - val_loss: 0.9905 - val_acc: 0.8750\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6945 - acc: 0.8333 - val_loss: 0.9857 - val_acc: 0.8750\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.7053 - acc: 0.8281 - val_loss: 0.9834 - val_acc: 0.8750\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3348 - acc: 0.6667 - val_loss: 0.9789 - val_acc: 0.8750\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.6503 - acc: 0.8438 - val_loss: 0.9798 - val_acc: 0.8750\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.3720 - acc: 0.5000 - val_loss: 0.9887 - val_acc: 0.8750\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6673 - acc: 0.8333 - val_loss: 0.9971 - val_acc: 0.8750\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.7735 - acc: 0.8125 - val_loss: 0.9996 - val_acc: 0.8750\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.0233 - acc: 0.6667 - val_loss: 1.0055 - val_acc: 0.8750\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.7512 - acc: 0.8281 - val_loss: 1.0103 - val_acc: 0.8750\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.7648 - acc: 0.8125 - val_loss: 1.0227 - val_acc: 0.8750\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7040 - acc: 0.8333 - val_loss: 1.0479 - val_acc: 0.8750\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.5714 - acc: 0.5000 - val_loss: 1.0438 - val_acc: 0.8750\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.6894 - acc: 0.8438 - val_loss: 1.0449 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy \n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Label Prediction\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows chart in a popup. Close to keep going\n",
    "#chart = cv2.imread('figure.png',1)\n",
    "#cv2.imshow('Results',chart)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape original input data images for predicting\n",
    "img_check = np.array(img_list, dtype =\"float\")/225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsMade = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all data through the prediction model that was created\n",
    "for i in range (0,len(img_check)):\n",
    "    predIndex = np.where(preds[i] == np.amax(preds[i]))\n",
    "    prediction = int(predIndex[0][0])\n",
    "    predictionsMade.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many correct predictions were made\n",
    "correct = 0\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    if(predictionsMade[i] == yset[i]):\n",
    "        correct += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(correct/len(yset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate back to original csv label names\n",
    "finalPred = []\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    finalPred.append(yval_label[predictionsMade[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new column\n",
    "df['#predictions'] = finalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new file name and save\n",
    "new_file =  csv_file[:-4]+'_v1.csv'\n",
    "df.to_csv(new_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input survey name here:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e6ee86d1f460d81df211628c36fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee33c6faecb4de6a8a0c1e73ad2e8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Input survey name\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text()\n",
    "output_text = widgets.Text()\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "input_text.on_submit(bind_input_to_output)\n",
    "\n",
    "print(\"Input survey name here:\")\n",
    "# Display input text box widget for input\n",
    "display(input_text)\n",
    "\n",
    "display(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey name is: balthus_survey_analysis\n"
     ]
    }
   ],
   "source": [
    "#Print survey name\n",
    "survey_name = output_text.value\n",
    "print(\"Survey name is:\", survey_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "http://localhost:3001/main/file=Zeppelin-V-Alt_balthus_survey_analysis.csv&views=111000&view=grid\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "upload_url = \"http://localhost:3001/uploadCSV\"\n",
    "dzc_url = 'http://localhost:3001/imageserver/balthus/balthus.dzc'\n",
    "upload_data = {'name': survey_name, 'dzc': dzc_url, 'user':user}\n",
    "files = {\"file\": open(new_file, \"rb\")}\n",
    "r = requests.post(upload_url, files=files, data=upload_data)\n",
    "print(r.status_code, r.reason)\n",
    "\n",
    "regex = re.compile('[^0-9a-zA-Z_]')\n",
    "survey_url = survey_name\n",
    "survey_url =  regex.sub('_', survey_url)\n",
    "\n",
    "url = \"http://localhost:3001/main/file=\" + user + \"_\" + survey_url + \".csv\" + \"&views=111000&view=grid\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
