{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuAVE Image to Label CNN Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function getQueryStringValue (key)\n",
       "{  \n",
       "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
       "}\n",
       "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all packages (this might take a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K\n",
    "from lenet import LeNet\n",
    "\n",
    "# More imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# import the necessary packages for SVM predictor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imutils\n",
    "\n",
    "# Import widget functionality\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the number of times the model will loop and its batch size for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a2472e2c9742d6b5a83e87f9655de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='epoch_count', options={'25 Iterations': 25, '50 Iterations': 50, '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochCount = {\n",
    "    '25 Iterations': 25,\n",
    "    '50 Iterations': 50,\n",
    "    '75 Iterations': 75\n",
    "}\n",
    "\n",
    "num_epochs = 0\n",
    "def f(epoch_count):\n",
    "    num_epochs = epoch_count\n",
    "    return epoch_count\n",
    "\n",
    "epochNum = interact(f, epoch_count=epochCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f59fc43419421a830e46ea7665d42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='batch_size', options={'64 Batch Size': 64, '32 Batch Size': 32, '1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batchS = {\n",
    "    '32 Batch Size': 32,\n",
    "    '64 Batch Size': 64,\n",
    "    '128 Batch Size': 128\n",
    "}\n",
    "\n",
    "def f(batch_size):\n",
    "    return batch_size\n",
    "\n",
    "batchNum = interact(f, batch_size=batchS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the number of epochs to train for, init learning rate and batch size\n",
    "EPOCHS = epochNum.widget.result\n",
    "INIT_LR = 1e-3\n",
    "BS = batchNum.widget.result\n",
    "# init the image suffix, yset, and image list\n",
    "suffix = '.jpg'\n",
    "img_list = []\n",
    "yset = []\n",
    "# create labels list and 2 dicts for 2 way mapping\n",
    "labels = []\n",
    "# key = label value = number\n",
    "label_yval = dict()\n",
    "# key = number value = label\n",
    "yval_label = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and choose the column name that coresponds with the column label to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d942ea30be1e4614bbbee5c59c1f6ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='predictions_menu', options={'Co ppm (INAA)#number': 'Co ppm (INAA)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use csv file to grab images/labels\n",
    "csv_path = \"../../temp_csvs/\" + csv_file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "#generate image path\n",
    "lower_case_csv = csv_file.lower()\n",
    "img_path = \"../../images/\" + lower_case_csv.split(\".\")[0]\n",
    "\n",
    "# Choose column of label for prediction\n",
    "toPredict = list(df.columns.values)\n",
    "\n",
    "pred_menu = {}\n",
    "for i in range(0, len(toPredict)):\n",
    "    pred_menu[toPredict[i]] = toPredict[i]\n",
    "\n",
    "def f(predictions_menu):\n",
    "    return predictions_menu\n",
    "# choose which label for predictions\n",
    "out2 = interact(f, predictions_menu=pred_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the images and configure them for predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This might take a little while depending on the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab chosen column names\n",
    "nameCol = df['#img']\n",
    "predCol = df[out2.widget.result]\n",
    "\n",
    "# add all fabric columns to the y set\n",
    "for i in range (0,len(predCol)):\n",
    "    labels.append(predCol[i])\n",
    "\n",
    "# grab all unique labels\n",
    "uni_labels = set(labels)\n",
    "uni_labels = list(uni_labels)\n",
    "\n",
    "# assign each label a dict key number\n",
    "for i in range(0,len(uni_labels)):\n",
    "    yval_label[i] = uni_labels[i]\n",
    "    label_yval[uni_labels[i]] = i\n",
    "\n",
    "# create list of keys associated with their labels\n",
    "for i in range (0, len(labels)):\n",
    "    yset.append(label_yval[labels[i]])\n",
    "    \n",
    "# gather images from path created from file names in csv file\n",
    "for i in range (0,len(nameCol)):\n",
    "    base_filename = nameCol[i]\n",
    "    fileName = os.path.join(img_path, base_filename + suffix)\n",
    "    im = cv2.imread(fileName)\n",
    "    im = cv2.resize(im, (28,28))\n",
    "    im = img_to_array(im)\n",
    "    img_list.append(im)\n",
    "\n",
    "# Shuffle the data\n",
    "p = np.random.permutation(len(yset))\n",
    "\n",
    "# Relable for splitting sets\n",
    "Y = []\n",
    "X = []\n",
    "for i in range(0,len(yset)):\n",
    "    Y.append(yset[p[i]])\n",
    "    X.append(img_list[p[i]])\n",
    "    \n",
    "# split the test and training set 75:25\n",
    "split = int(len(X)*(.75))\n",
    "xtrain = X[:split]\n",
    "xtest = X[split:]\n",
    "ytrain = Y[:split]\n",
    "ytest = Y[split:]\n",
    "\n",
    "# transform to arrays\n",
    "trainX = np.array(xtrain, dtype=\"float\")/225.0\n",
    "testX = np.array(xtest, dtype =\"float\")/225.0\n",
    "\n",
    "ytrain = np.array(ytrain)\n",
    "ytest = np.array(ytest)\n",
    "\n",
    "# parsed Y data containers\n",
    "trainY = []\n",
    "testY = []\n",
    "\n",
    "# convert labels from int to vectors\n",
    "trainY = np_utils.to_categorical(ytrain,len(uni_labels))\n",
    "testY = np_utils.to_categorical(ytest,len(uni_labels))\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")\n",
    "# initialize the model\n",
    "model = LeNet.build(width=28, height=28, depth=3, classes=len(uni_labels))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is relative to the size of the data set and may take a few minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 2.9352 - acc: 0.1320 - val_loss: 2.8276 - val_acc: 0.2159\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 2.7402 - acc: 0.1797 - val_loss: 2.8329 - val_acc: 0.1136\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - 1s 364ms/step - loss: 2.6510 - acc: 0.2042 - val_loss: 3.0561 - val_acc: 0.2159\n",
      "Epoch 4/25\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 2.6752 - acc: 0.2031 - val_loss: 2.7509 - val_acc: 0.1818\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 2.6323 - acc: 0.2814 - val_loss: 2.7920 - val_acc: 0.1818\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 2.7169 - acc: 0.1881 - val_loss: 2.7758 - val_acc: 0.1818\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 2.5853 - acc: 0.1992 - val_loss: 2.7254 - val_acc: 0.1818\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 2.4072 - acc: 0.2979 - val_loss: 3.3521 - val_acc: 0.1818\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - 2s 487ms/step - loss: 2.6841 - acc: 0.2348 - val_loss: 2.6390 - val_acc: 0.2045\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 2s 498ms/step - loss: 2.6479 - acc: 0.2896 - val_loss: 2.6858 - val_acc: 0.2045\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - 2s 466ms/step - loss: 2.5193 - acc: 0.2636 - val_loss: 3.1008 - val_acc: 0.1818\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - 2s 510ms/step - loss: 2.6170 - acc: 0.2417 - val_loss: 2.7083 - val_acc: 0.1818\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 2.5169 - acc: 0.3049 - val_loss: 2.7456 - val_acc: 0.2727\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 2.4817 - acc: 0.2969 - val_loss: 2.8143 - val_acc: 0.2841\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 2.5359 - acc: 0.2694 - val_loss: 2.7429 - val_acc: 0.2273\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 2.2714 - acc: 0.4064 - val_loss: 2.6080 - val_acc: 0.2727\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 2.5878 - acc: 0.3119 - val_loss: 2.9837 - val_acc: 0.2500\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 2.4186 - acc: 0.3284 - val_loss: 2.7850 - val_acc: 0.2500\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 2.5460 - acc: 0.2789 - val_loss: 2.5896 - val_acc: 0.3182\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 2.3354 - acc: 0.3477 - val_loss: 2.7129 - val_acc: 0.3182\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 2s 466ms/step - loss: 2.3520 - acc: 0.3572 - val_loss: 2.9921 - val_acc: 0.2727\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 2.3263 - acc: 0.2969 - val_loss: 2.7241 - val_acc: 0.2727\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 2.1830 - acc: 0.4162 - val_loss: 3.3006 - val_acc: 0.2500\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 2.3641 - acc: 0.3407 - val_loss: 2.7025 - val_acc: 0.2955\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 2.3513 - acc: 0.3407 - val_loss: 2.9488 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the original data and predict based on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26704545454545453\n"
     ]
    }
   ],
   "source": [
    "# Reshape original input data images for predicting\n",
    "img_check = np.array(img_list, dtype =\"float\")/225.0\n",
    "\n",
    "predictionsMade = []\n",
    "preds = model.predict(img_check)\n",
    "\n",
    "# Run all data through the prediction model that was created\n",
    "for i in range (0,len(img_check)):\n",
    "    predIndex = np.where(preds[i] == np.amax(preds[i]))\n",
    "    prediction = int(predIndex[0][0])\n",
    "    predictionsMade.append(prediction)\n",
    "    \n",
    "# Count how many correct predictions were made\n",
    "correct = 0\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    if(predictionsMade[i] == yset[i]):\n",
    "        correct += 1 \n",
    "        \n",
    "print(\"Accuracy: \" + str(correct/len(yset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate model file and save\n",
    "modelName = user + \"_cnn_\" + out2.widget.result + \"_\" + str(epochCount) + \"_\" + str(batchS) + \".h5\"\n",
    "modelPath = \"models/\"\n",
    "\n",
    "model.save(os.path.join(modelPath, modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "from keras.models import load_model\n",
    "model2 = load_model(os.path.join(modelPath, modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsMade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter a new header for the prediction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input new column Header Label: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5101a2a255be42449b03612e96e72fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Type label here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095fa4745d194cf69707d0f682e6cff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='New Header will be displayed here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Translate back to original csv label names\n",
    "finalPred = []\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    finalPred.append(yval_label[predictionsMade[i]])\n",
    "\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text(\n",
    "    value=None,\n",
    "    placeholder='Type label here',\n",
    "    disabled=False\n",
    ")\n",
    "output_text = widgets.Text(\n",
    "    value=None,\n",
    "    placeholder='New Header will be displayed here',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "input_text.observe(bind_input_to_output)\n",
    "\n",
    "print(\"Input new column Header Label: \")\n",
    "\n",
    "display(input_text)\n",
    "display(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the predictions back to the original CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kommos_j_test_1\n"
     ]
    }
   ],
   "source": [
    "# Append the new column w/ it's new column name\n",
    "df[input_text.value] = finalPred\n",
    "print(input_text.value)\n",
    "\n",
    "# new file name\n",
    "new_file =  csv_file[:-4]+'_v1.csv'\n",
    "df.to_csv(new_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input survey name here:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bfb4f54ab4447a937b61814be0e71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bab7b6fe3504ae28707a82b2e4d3bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Input survey name\n",
    "\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text()\n",
    "output_text = widgets.Text()\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "input_text.observe(bind_input_to_output)\n",
    "\n",
    "print(\"Input survey name here:\")\n",
    "# Display input text box widget for input\n",
    "display(input_text)\n",
    "\n",
    "display(output_text)\n",
    "\n",
    "survey_name = output_text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kommos_j_test_1\n",
      "https://bioregional.ucsd.edu/suave/surveys/kommos_Oct2017/kommos_Oct2017.dzc\n"
     ]
    }
   ],
   "source": [
    "print(input_text.value)\n",
    "print(dzc_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "https://suave-dev.sdsc.edu/main/file=zaslavsk_.csv&views=1110001&view=grid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "upload_url = \"http://suave.sdsc.edu:3001/uploadCSV\"\n",
    "upload_data = {'name': input_text.value, 'dzc': dzc_file, 'user':user}\n",
    "files = {\"file\": open(new_file, \"rb\")}\n",
    "r = requests.post(upload_url, files=files, data=upload_data)\n",
    "print(r.status_code, r.reason)\n",
    "\n",
    "regex = re.compile('[^0-9a-zA-Z_]')\n",
    "survey_url = survey_name\n",
    "survey_url =  regex.sub('_', survey_url)\n",
    "\n",
    "url = \"https://suave-dev.sdsc.edu/main/file=\" + user + \"_\" + input_text.value + \".csv\" + \"&views=1110001&view=grid\"\n",
    "print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
